{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.get_detector import get_model\n",
    "\n",
    "import cv2\n",
    "import requests\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from src.setup import Setup\n",
    "\n",
    "class Censor():\n",
    "    def __init__(self) -> None:\n",
    "        Setup().model_downloader()\n",
    "        self.model = get_model()\n",
    "        self.classes = self.model.names\n",
    "    \n",
    "    def detect(self, image_path, is_local=False):\n",
    "        image = Image.open(requests.get(image_path, stream=True).raw).convert(\"RGB\")\n",
    "        results = self.model(image)\n",
    "        texts = []\n",
    "        boxes = []\n",
    "        for result in results.xyxy[0]:\n",
    "            result = map(float, result)\n",
    "            x1, y1, x2, y2, score, class_idx = result\n",
    "            text = f\"{self.classes[int(class_idx)]} {score:0.2f}\"\n",
    "            boxes.append([x1, y1, x2, y2])\n",
    "            texts.append(text)\n",
    "        return np.array(image), boxes, texts\n",
    "    \n",
    "    def visualize(image, texts, boxes):\n",
    "        image = np.array(image)\n",
    "        img = image.copy()\n",
    "        for box, text in zip(boxes, texts):\n",
    "            x1, y1, x2, y2 = box\n",
    "            img = cv2.rectangle(img, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "            img = cv2.putText(img, text, (int(x1), int(y1)-10), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,0,0), 1)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "def visualize_ocr(image, texts, boxes):\n",
    "    image = np.array(image)\n",
    "    img = image.copy()\n",
    "    for box, text in zip(boxes, texts):\n",
    "        x1, y1, x2, y2 = box\n",
    "        img = cv2.rectangle(img, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "        img = cv2.putText(img, text, (int(x1), int(y1)-10), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,0,0), 1)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.censor import Censor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 ðŸš€ 2023-9-7 Python-3.9.17 torch-2.0.1+cu117 CPU\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mrequirements:\u001b[0m /home/linh/hahalolo/streamlit_app/social_media_censorship/storage/requirements.txt not found, check failed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n",
      "Model summary: 476 layers, 76249428 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "censor = Censor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[162, 188, 213],\n",
       "         [161, 187, 212],\n",
       "         [161, 187, 212],\n",
       "         ...,\n",
       "         [214, 216, 229],\n",
       "         [214, 216, 229],\n",
       "         [214, 216, 229]],\n",
       " \n",
       "        [[163, 189, 214],\n",
       "         [162, 188, 213],\n",
       "         [161, 187, 212],\n",
       "         ...,\n",
       "         [214, 216, 229],\n",
       "         [214, 216, 229],\n",
       "         [214, 216, 229]],\n",
       " \n",
       "        [[164, 190, 215],\n",
       "         [163, 189, 214],\n",
       "         [162, 188, 213],\n",
       "         ...,\n",
       "         [214, 216, 229],\n",
       "         [214, 216, 229],\n",
       "         [214, 216, 229]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 31,  38,  46],\n",
       "         [ 32,  39,  47],\n",
       "         [ 34,  41,  49],\n",
       "         ...,\n",
       "         [ 80,  91, 111],\n",
       "         [ 82,  93, 115],\n",
       "         [ 85,  96, 118]],\n",
       " \n",
       "        [[ 31,  38,  46],\n",
       "         [ 32,  39,  47],\n",
       "         [ 34,  41,  49],\n",
       "         ...,\n",
       "         [ 81,  92, 112],\n",
       "         [ 82,  93, 115],\n",
       "         [ 86,  97, 119]],\n",
       " \n",
       "        [[ 31,  38,  46],\n",
       "         [ 32,  39,  47],\n",
       "         [ 34,  41,  49],\n",
       "         ...,\n",
       "         [ 82,  93, 111],\n",
       "         [ 84,  95, 115],\n",
       "         [ 87,  98, 118]]], dtype=uint8),\n",
       " [[894.406494140625, 649.1490478515625, 1878.7177734375, 1063.3287353515625]],\n",
       " ['gun 0.65'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "censor.detect(\"https://www.outdoorlife.com/uploads/2023/05/02/opener-scaled.jpg?auto=webp\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "social_media_censorship",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
